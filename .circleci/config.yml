# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
# Use a package of configuration called an orb.
orbs:
  # Choose either one of the orbs below
  # Declare a dependency on the welcome-orb
  # welcome: circleci/welcome-orb@0.4.1
  aws-cli: circleci/aws-cli@2.0.3

default_containers: &defaultCon
  docker:
  - image: cimg/base:stable
### COmmands:
commands: # a reusable command with parameters
  print_pipeline_id:
    parameters:
      to:
        type: string
        default: "No provided ID"
    steps:
      - run: echo << parameters.to >>
  
    # Exercise - Rollback
  destroy_environment_on_fail:
    steps:
      - run:
          name: Destroy environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}
  
  destroy_environment:
    steps:
      - run:
          name: Destroy environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
          # when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:
  say-hello:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    <<: *defaultCon
    # A<<: *defaultCondd steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      - checkout
      - run:
          name: "Say hello"
          command: "echo Hello, World!"

  print_hello:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    <<: *defaultCon
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      - checkout
      - run:
          name: "Say hello"
          command: "echo Hello Ragobaaaaaaaaaa"

  print_world:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    <<: *defaultCon
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      - checkout
      - run:
          name: "Say World"
          command: "echo World!"


  print_my_name:
    <<: *defaultCon
    steps:
      - checkout
      - run:
          name: "Print My name"
          command: "echo $coder_name>> logs"
      - run:
          name: "Print My logs"
          command: "cat logs"
      - run:
          name: "echo an env var that is part of our project"
          command: |
            echo $coder_name


  save_hello_world_output:
    <<: *defaultCon
    steps:
      - checkout
      - run:
          name: "Echo text to file"
          command: |
            echo "Echoing some text to file" > ~/my_file.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - my_file.txt


  print_output_file:
    <<: *defaultCon
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/data
      - run: cat /tmp/data/my_file.txt

  test_command_in_job:
    <<: *defaultCon
    steps:
      - checkout
      - print_pipeline_id :
          to: ${CIRCLE_WORKFLOW_ID}
            
  create_infrastructure: 
    docker:
      - image: amazon/aws-cli
    steps:
      # - run: apk add --update openssh-client git
      - checkout
      - run:
          name: Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
              --template-file template.yml \
              --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
              --region us-east-1
      - run:
          name: Build inventory file
          command: |
            echo [all] > ~/inventory
            aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text >> ~/inventory
      - run:
          name: Install tar utility
          command: |
            yum install -y tar gzip
      - persist_to_workspace:
          root: ~/
          paths:
            - inventory
      
      - destroy_environment_on_fail
  # Exercise: Config and Deployment
  configure_infrastructure: 
    docker:
      - image: python:3.11.0rc2-alpine3.16
    steps:
      - checkout
      - add_ssh_keys:
              # You can get this ID in the section where you registered the SSH Key
              fingerprints: ["5e:5b:b7:bf:cb:0b:2a:1f:51:fd:89:01:b8:73:f9:a8"] 
      - run:
          name: Install Ansible
          command: |
            # Install Ansible
            apk add --update ansible
      - attach_workspace:
          at: ~/myinv
      - run:
          name: Run Playbook and Configure server
          command: |
            # Your command
            ansible-playbook -i ~/myinv/inventory -vvv main.yml

  smoke_test:
    docker:
      - image: alpine:latest
    steps:
      - run: apk add --update curl
      - run:
          name: smoke test
          command: |
            URL="https://blog.udacity.com/"
            # Test if website exists
            if curl -s --head ${URL} 
            then
              return 0
            else
              return 1
            fi
      - destroy_environment_on_fail
  
  # Exercise: Smoke Testing
  smoke_test_on_fail:
    docker:
      - image: alpine:latest
    steps:
      - run:
          name: Test job
          # Fail the job intentionally to simulate an error.
          command:  return 1
      - destroy_environment_on_fail  
  
  # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
# Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
create_and_deploy_front_end:
  docker:
    - image: amazon/aws-cli
  steps:
    - checkout
    - run:
        name: Execute bucket.yml - Create Cloudformation Stack
        command: |
          aws cloudformation deploy \
          --template-file bucket.yml \
          --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
          --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
    # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
    - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete
      
  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
get_last_deployment_id:
  docker:
    - image: amazon/aws-cli
  steps:
    - checkout
    - run: yum install -y tar gzip
    - run:
        name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
        command: |
          aws cloudformation \
          list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
          --no-paginate --output text > ~/textfile.txt
    - persist_to_workspace:
        root: ~/
        paths: 
          - textfile.txt 

  # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
# Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
promote_to_production:
  docker:
    - image: amazon/aws-cli
  steps:
    - checkout
    - run:
        name: Execute cloudfront.yml
        command: |
          aws cloudformation deploy \
          --template-file cloudfront.yml \
          --stack-name production-distro \
          --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

  # Destroy the previous production version's S3 bucket and CloudFormation stack. 
clean_up_old_front_end:
  docker:
    - image: amazon/aws-cli
  steps:
    - checkout
    - run: yum install -y tar gzip
    - attach_workspace:
        at: ~/
    - run:
        name: Destroy the previous S3 bucket and CloudFormation stack. 
        # Use $OldBucketID environment variable or mybucket644752792305 below.
        # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
        command: |
          export OldBucketID=$(cat ~/textfile.txt)
          aws s3 rm "s3://${OldBucketID}" --recursive


  test_on_fail_step:
    <<: *defaultCon
    steps:
      - checkout
      - run: exit 1

      - run:
          name: Test on Fail
          command: echo "Hello Error!"
          when: on_fail

  clear_stack:
    docker:
      - image: amazon/aws-cli
    steps:
      - destroy_environment
# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  my_workflow:
    jobs:
      - create_and_deploy_front_end
      - promote_to_production:
          requires: 
            - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production
    # ansible_00:
  #   jobs:
      # - say-hello
      # - print_hello
      # - print_world:
      #     requires:
      #     - print_hello
      # - print_my_name:
      #     requires:
      #       - print_world
      # - save_hello_world_output
      # - print_output_file:
      #     requires:
      #       - save_hello_world_output
      # - test_command_in_job
      # - test_on_fail_step

      # - create_infrastructure
      # - configure_infrastructure:
      #     requires:
      #       - create_infrastructure
      # - smoke_test:
      #     requires:
      #       - configure_infrastructure
      # - smoke_test_on_fail:
      #     requires:
      #       - smoke_test
      # - clear_stack:
      #     requires:
      #       - smoke_test_on_fail
      
